[
  {
    "train_losses": [
      3.095069556009202,
      2.5801543394724527,
      2.453416604844351,
      2.3769772582583957,
      2.3280817062135726,
      2.2875061905573286,
      2.2545168134901257,
      2.226544769983443,
      2.2010861124311174,
      2.185660479560731,
      2.167262247630528,
      2.153877572407798,
      2.1377024499196855,
      2.140675809648302,
      2.122681462575519,
      2.121727701217409,
      2.1201585815066384,
      2.125523396900722,
      2.11351197863382,
      2.121182839075724
    ],
    "val_losses": [
      2.6666036333356584,
      2.473175355366298,
      2.388740198952811,
      2.3154123510633196,
      2.252763339451381,
      2.21736546925136,
      2.1767216750553677,
      2.1409666538238525,
      2.1304021903446744,
      2.10298000063215,
      2.1131204536982944,
      2.0994791984558105,
      2.0714468955993652,
      2.0653666087559293,
      2.0504143919263567,
      2.0666231427873885,
      2.0459021840776717,
      2.0804454939705983,
      2.0929877928325107,
      2.069648708615984
    ],
    "learning_rates": [
      0.0003,
      0.00029815940691897306,
      0.0002926829491861254,
      0.00028370547536616097,
      0.00027144804065905466,
      0.0002562124637873889,
      0.00023837389521772474,
      0.00021837157971106225,
      0.00019669804065905466,
      0.00017388695252351454,
      0.0001505,
      0.0001271130474764855,
      0.00010430195934094536,
      8.262842028893775e-05,
      6.262610478227527e-05,
      4.478753621261114e-05,
      2.9551959340945366e-05,
      1.7294524633839014e-05,
      8.317050813874547e-06,
      2.84059308102692e-06
    ],
    "best_val_loss": 2.0459021840776717,
    "num_params": 952261,
    "final_train_loss": 2.121182839075724,
    "final_val_loss": 2.069648708615984,
    "experiment_name": "Baseline (完整模型)",
    "config": {
      "d_model": 128,
      "num_heads": 4,
      "num_encoder_layers": 2,
      "num_decoder_layers": 2,
      "d_ff": 512,
      "dropout": 0.1,
      "batch_size": 32,
      "learning_rate": 0.0003,
      "epochs": 20,
      "seq_length": 50,
      "seed": 42,
      "data_path": "D:\\1_Learn_Bjtu\\Model_Work\\data\\tiny_shakespeare.txt",
      "grad_clip": 1.0,
      "scheduler": "cosine",
      "weight_decay": 0.01,
      "use_cuda": true,
      "step_size": 10,
      "gamma": 0.8,
      "warmup_steps": 5
    }
  },
  {
    "train_losses": [
      3.2564258991725863,
      2.701211887692648,
      2.56168794631958,
      2.4935166078900535,
      2.4549031181940957,
      2.4185291207025923,
      2.3861235172029525,
      2.3662712574005127,
      2.3491336012643482,
      2.340408442512391,
      2.3240675131479898,
      2.3103152645958795,
      2.3014209573231046,
      2.2955180766090515,
      2.287068385926504,
      2.2908841731056335,
      2.2835849693843295,
      2.2793154148828414,
      2.287809833647713,
      2.283324128105527
    ],
    "val_losses": [
      2.8018936770302907,
      2.597459214074271,
      2.472613504954747,
      2.4255361216408864,
      2.3882701056344167,
      2.3501693521227156,
      2.3455721650804793,
      2.313105515071324,
      2.307198796953474,
      2.31588990347726,
      2.283541236604963,
      2.277081251144409,
      2.239067724772862,
      2.255234922681536,
      2.256888048989432,
      2.264265980039324,
      2.2610436167035783,
      2.232791083199637,
      2.2324728625161305,
      2.2565547057560513
    ],
    "learning_rates": [
      0.0003,
      0.00029815940691897306,
      0.0002926829491861254,
      0.00028370547536616097,
      0.00027144804065905466,
      0.0002562124637873889,
      0.00023837389521772474,
      0.00021837157971106225,
      0.00019669804065905466,
      0.00017388695252351454,
      0.0001505,
      0.0001271130474764855,
      0.00010430195934094536,
      8.262842028893775e-05,
      6.262610478227527e-05,
      4.478753621261114e-05,
      2.9551959340945366e-05,
      1.7294524633839014e-05,
      8.317050813874547e-06,
      2.84059308102692e-06
    ],
    "best_val_loss": 2.2324728625161305,
    "num_params": 489413,
    "final_train_loss": 2.283324128105527,
    "final_val_loss": 2.2565547057560513,
    "experiment_name": "单层编码器",
    "config": {
      "d_model": 128,
      "num_heads": 4,
      "num_encoder_layers": 1,
      "num_decoder_layers": 1,
      "d_ff": 512,
      "dropout": 0.1,
      "batch_size": 32,
      "learning_rate": 0.0003,
      "epochs": 20,
      "seq_length": 50,
      "seed": 42,
      "data_path": "D:\\1_Learn_Bjtu\\Model_Work\\data\\tiny_shakespeare.txt",
      "grad_clip": 1.0,
      "scheduler": "cosine",
      "weight_decay": 0.01,
      "use_cuda": true,
      "step_size": 10,
      "gamma": 0.8,
      "warmup_steps": 5
    }
  },
  {
    "train_losses": [
      3.0362918036324635,
      2.516802674248105,
      2.374673192463224,
      2.2846118836175826,
      2.228496101167467,
      2.1877147545890203,
      2.1490703650883267,
      2.1145371747395347,
      2.0860878891415067,
      2.0646570485735696,
      2.041787794658116,
      2.025068790193588,
      2.0032366514205933,
      2.000797975630987,
      1.9810607773917062,
      1.9765068443994673,
      1.9748410213561285,
      1.9794256989918058,
      1.9643982629927377,
      1.969936421939305
    ],
    "val_losses": [
      2.6312643800462996,
      2.443392242704119,
      2.3508949960981096,
      2.2815048694610596,
      2.2184249673570906,
      2.1808969974517822,
      2.136542320251465,
      2.1010152271815707,
      2.0908713340759277,
      2.066644157682146,
      2.066004310335432,
      2.0563363007136752,
      2.018065469605582,
      2.0141423429761613,
      2.0006023985998973,
      2.019349064145769,
      1.9980562244142805,
      2.028929131371634,
      2.038960439818246,
      2.015353185789926
    ],
    "learning_rates": [
      0.0003,
      0.00029815940691897306,
      0.0002926829491861254,
      0.00028370547536616097,
      0.00027144804065905466,
      0.0002562124637873889,
      0.00023837389521772474,
      0.00021837157971106225,
      0.00019669804065905466,
      0.00017388695252351454,
      0.0001505,
      0.0001271130474764855,
      0.00010430195934094536,
      8.262842028893775e-05,
      6.262610478227527e-05,
      4.478753621261114e-05,
      2.9551959340945366e-05,
      1.7294524633839014e-05,
      8.317050813874547e-06,
      2.84059308102692e-06
    ],
    "best_val_loss": 1.9980562244142805,
    "num_params": 952261,
    "final_train_loss": 1.969936421939305,
    "final_val_loss": 2.015353185789926,
    "experiment_name": "无Dropout",
    "config": {
      "d_model": 128,
      "num_heads": 4,
      "num_encoder_layers": 2,
      "num_decoder_layers": 2,
      "d_ff": 512,
      "dropout": 0.0,
      "batch_size": 32,
      "learning_rate": 0.0003,
      "epochs": 20,
      "seq_length": 50,
      "seed": 42,
      "data_path": "D:\\1_Learn_Bjtu\\Model_Work\\data\\tiny_shakespeare.txt",
      "grad_clip": 1.0,
      "scheduler": "cosine",
      "weight_decay": 0.01,
      "use_cuda": true,
      "step_size": 10,
      "gamma": 0.8,
      "warmup_steps": 5
    }
  },
  {
    "train_losses": [
      3.5369033018747964,
      2.9487198004646906,
      2.7139123053777787,
      2.606949840273176,
      2.540310333645533,
      2.4913896643926225,
      2.4493541036333357,
      2.4274424825395857,
      2.4059577480195062,
      2.392432829690358,
      2.371753344460139,
      2.37305510233319,
      2.3637733573005315,
      2.3466822571224637,
      2.3443894424135725,
      2.339606031538948,
      2.3375815966772655,
      2.3376186423831515,
      2.3351260631803483,
      2.3392185559348455
    ],
    "val_losses": [
      3.1158712250845775,
      2.782612153462001,
      2.589242901120867,
      2.534123318535941,
      2.438366855893816,
      2.3775595937456404,
      2.3852971962520053,
      2.3466299942561557,
      2.331994192940848,
      2.3409976278032576,
      2.307598965508597,
      2.3004908561706543,
      2.2633278710501537,
      2.278583254132952,
      2.2614385400499617,
      2.2769547530582974,
      2.2584806169782365,
      2.289185115269252,
      2.2717793669019426,
      2.292905194418771
    ],
    "learning_rates": [
      0.0003,
      0.00029815940691897306,
      0.0002926829491861254,
      0.00028370547536616097,
      0.00027144804065905466,
      0.0002562124637873889,
      0.00023837389521772474,
      0.00021837157971106225,
      0.00019669804065905466,
      0.00017388695252351454,
      0.0001505,
      0.0001271130474764855,
      0.00010430195934094536,
      8.262842028893775e-05,
      6.262610478227527e-05,
      4.478753621261114e-05,
      2.9551959340945366e-05,
      1.7294524633839014e-05,
      8.317050813874547e-06,
      2.84059308102692e-06
    ],
    "best_val_loss": 2.2584806169782365,
    "num_params": 246789,
    "final_train_loss": 2.3392185559348455,
    "final_val_loss": 2.292905194418771,
    "experiment_name": "小模型 (d_model=64)",
    "config": {
      "d_model": 64,
      "num_heads": 2,
      "num_encoder_layers": 2,
      "num_decoder_layers": 2,
      "d_ff": 256,
      "dropout": 0.1,
      "batch_size": 32,
      "learning_rate": 0.0003,
      "epochs": 20,
      "seq_length": 50,
      "seed": 42,
      "data_path": "D:\\1_Learn_Bjtu\\Model_Work\\data\\tiny_shakespeare.txt",
      "grad_clip": 1.0,
      "scheduler": "cosine",
      "weight_decay": 0.01,
      "use_cuda": true,
      "step_size": 10,
      "gamma": 0.8,
      "warmup_steps": 5
    }
  },
  {
    "train_losses": [
      2.7973426637195407,
      2.3818203116220142,
      2.2548321504441518,
      2.183769536396814,
      2.119181511894105,
      2.075454499986437,
      2.0448068418200056,
      2.0272178933733986,
      1.9987499259767079,
      1.974526393981207,
      1.9623934200831823,
      1.9447561105092366,
      1.9294220398342798,
      1.923163722431849,
      1.9135824877118308,
      1.9043352187625946,
      1.900342167369903,
      1.892247480059427,
      1.896545446108258,
      1.8950417079622783
    ],
    "val_losses": [
      2.449223620550973,
      2.2809207439422607,
      2.191448143550328,
      2.1268022060394287,
      2.051785843712943,
      2.0005198206220354,
      1.9999020780835832,
      1.9717345067432948,
      1.9263097729001726,
      1.9482330765042986,
      1.9048591341291154,
      1.9201505013874598,
      1.861009189060756,
      1.887415545327323,
      1.8494725397654943,
      1.8627271481922694,
      1.838822398866926,
      1.8563989741461617,
      1.8851498195103236,
      1.8481591258730208
    ],
    "learning_rates": [
      0.0003,
      0.00029815940691897306,
      0.0002926829491861254,
      0.00028370547536616097,
      0.00027144804065905466,
      0.0002562124637873889,
      0.00023837389521772474,
      0.00021837157971106225,
      0.00019669804065905466,
      0.00017388695252351454,
      0.0001505,
      0.0001271130474764855,
      0.00010430195934094536,
      8.262842028893775e-05,
      6.262610478227527e-05,
      4.478753621261114e-05,
      2.9551959340945366e-05,
      1.7294524633839014e-05,
      8.317050813874547e-06,
      2.84059308102692e-06
    ],
    "best_val_loss": 1.838822398866926,
    "num_params": 3739461,
    "final_train_loss": 1.8950417079622783,
    "final_val_loss": 1.8481591258730208,
    "experiment_name": "大模型 (d_model=256)",
    "config": {
      "d_model": 256,
      "num_heads": 8,
      "num_encoder_layers": 2,
      "num_decoder_layers": 2,
      "d_ff": 1024,
      "dropout": 0.1,
      "batch_size": 32,
      "learning_rate": 0.0003,
      "epochs": 20,
      "seq_length": 50,
      "seed": 42,
      "data_path": "D:\\1_Learn_Bjtu\\Model_Work\\data\\tiny_shakespeare.txt",
      "grad_clip": 1.0,
      "scheduler": "cosine",
      "weight_decay": 0.01,
      "use_cuda": true,
      "step_size": 10,
      "gamma": 0.8,
      "warmup_steps": 5
    }
  },
  {
    "train_losses": [
      2.987242305089557,
      2.5033112934657504,
      2.3696295496017212,
      2.295609746660505,
      2.2300489592173744,
      2.1786490167890276,
      2.138489817816114,
      2.1065404112376864,
      2.077608034724281,
      2.0564925065116277,
      2.035517730410137,
      2.0274666755918473,
      2.003128594822354,
      1.9951399886418903,
      1.9882742488195027,
      1.9759685122777546,
      1.9760940699350267,
      1.9666887351444788,
      1.9722220046179635,
      1.9734082240906974
    ],
    "val_losses": [
      2.5810424259730746,
      2.397044828959874,
      2.299104997089931,
      2.223167725971767,
      2.1487618514469693,
      2.1160222462245395,
      2.0709494182041714,
      2.030609335218157,
      2.007065142904009,
      1.9682904311588831,
      1.9756664718900407,
      1.9533387933458601,
      1.94109731061118,
      1.9234441007886613,
      1.89443462235587,
      1.9110915660858154,
      1.8977202006748743,
      1.9009256533214025,
      1.8938503435679845,
      1.8745150055204118
    ],
    "learning_rates": [
      0.0003,
      0.00029815940691897306,
      0.0002926829491861254,
      0.00028370547536616097,
      0.00027144804065905466,
      0.0002562124637873889,
      0.00023837389521772474,
      0.00021837157971106225,
      0.00019669804065905466,
      0.00017388695252351454,
      0.0001505,
      0.0001271130474764855,
      0.00010430195934094536,
      8.262842028893775e-05,
      6.262610478227527e-05,
      4.478753621261114e-05,
      2.9551959340945366e-05,
      1.7294524633839014e-05,
      8.317050813874547e-06,
      2.84059308102692e-06
    ],
    "best_val_loss": 1.8745150055204118,
    "num_params": 1877957,
    "final_train_loss": 1.9734082240906974,
    "final_val_loss": 1.8745150055204118,
    "experiment_name": "更多层 (4层)",
    "config": {
      "d_model": 128,
      "num_heads": 4,
      "num_encoder_layers": 4,
      "num_decoder_layers": 4,
      "d_ff": 512,
      "dropout": 0.1,
      "batch_size": 32,
      "learning_rate": 0.0003,
      "epochs": 20,
      "seq_length": 50,
      "seed": 42,
      "data_path": "D:\\1_Learn_Bjtu\\Model_Work\\data\\tiny_shakespeare.txt",
      "grad_clip": 1.0,
      "scheduler": "cosine",
      "weight_decay": 0.01,
      "use_cuda": true,
      "step_size": 10,
      "gamma": 0.8,
      "warmup_steps": 5
    }
  }
]